{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "geo to zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tozipDataTemp = pd.read_csv('rowData\\\\zip_code_database.csv',encoding='latin1')\n",
    "tozipDataTemp = tozipDataTemp.loc[tozipDataTemp['state']=='NY']\n",
    "tozipDataTemp.columns\n",
    "tozipDataTemp = tozipDataTemp.drop(['type', 'decommissioned', 'primary_city', 'acceptable_cities',\\\n",
    "       'unacceptable_cities', 'state', 'county', 'timezone', 'area_codes','world_region', 'country',\\\n",
    "       'irs_estimated_population_2014'],axis=1)\n",
    "#tozipDataTemp.to_csv('data\\\\zip_code_database_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10952, 0.0],\n",
       " [10982, 0.00039999999999984086],\n",
       " [10977, 0.0010000000000000284],\n",
       " [10901, 0.0036000000000002727],\n",
       " [10954, 0.0052999999999988855]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return [zipcode, 4-neighbor zip area]\n",
    "# find neariest zip-code by zip-center long/lat database\n",
    "def trans_geo2zip(lat, long, retLen = 5, searchTreash=0.2):\n",
    "    tozipData = pd.read_csv('data\\\\zip_code_database_clean.csv')\n",
    "    #subData = tozipData\n",
    "    subData = tozipData.loc[tozipData['longitude']>=long-searchTreash]\n",
    "    subData = tozipData.loc[tozipData['longitude']<=long+searchTreash]\n",
    "    subData = tozipData.loc[tozipData['latitude']>=lat-searchTreash]\n",
    "    subData = tozipData.loc[tozipData['latitude']<=lat+searchTreash]\n",
    "    dis=[]\n",
    "    for index, row in subData.iterrows():\n",
    "        distance = (row['longitude']-long)**2+(row['latitude']-lat)**2\n",
    "        dis.append([int(row['zip']),distance])\n",
    "    dis.sort(key=lambda x:x[1])\n",
    "    #\n",
    "    ret = dis[:retLen]\n",
    "    return ret;\n",
    "trans_geo2zip(41.11,-74.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poplation - zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "populationDataDir = 'rowData\\population_by_zip_2010.csv'\n",
    "data = pd.read_csv(populationDataDir)\n",
    "#data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popuData = data.loc[data['gender'].isnull()]\n",
    "popuData = popuData.drop(['minimum_age','maximum_age','gender'], axis=1)\n",
    "#popuData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipData = pd.read_csv('rowData\\zip_code_database.csv', encoding='latin1')\n",
    "#zipData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipNYData = zipData.loc[zipData['state']=='NY'].zip.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popu = popuData.loc[popuData['zipcode'].isin(zipNYData)]\n",
    "outFileDir = 'data\\popu_zip.csv'\n",
    "###############popu.to_csv(outFileDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store - zip\n",
    "three features: total, #individual, #business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DCA License Number', 'License Type', 'License Expiration Date',\n",
       "       'License Category', 'Business Name', 'Business Name 2',\n",
       "       'Address Building', 'Address Street Name',\n",
       "       'Secondary Address Street Name', 'Address City', 'Address State',\n",
       "       'Address ZIP', 'Contact Phone Number', 'Address Borough', 'Detail',\n",
       "       'Longitude', 'Latitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeRowData = pd.read_csv('rowData\\Legally_Operating_Businesses.csv')\n",
    "storeRowData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address ZIP                0\n",
       "Address City               0\n",
       "DCA License Number         0\n",
       "License Type               0\n",
       "License Expiration Date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NaN\n",
    "storeRowData = storeRowData.fillna(0)\n",
    "storeRowData = storeRowData[storeRowData['Address ZIP'].astype('str').apply(lambda x : x.isnumeric())]\n",
    "#NYC city\n",
    "cityList = ['NEW YORK','BROOKLYN','QUEENS VILLAGE','JAMAICA','FLUSHING','BRONX','COLLEGE POINT']\n",
    "\n",
    "storesData = storeRowData[['Address ZIP','Address City','DCA License Number','License Type','License Expiration Date']]\\\n",
    "            .loc[storeRowData['Address ZIP'].astype('int64')<12000]\n",
    "storesData = storesData.loc[storesData['Address ZIP'].astype('int64')>10000]\n",
    "#print(len(storesData.index))\n",
    "#storesData.head(3)\n",
    "outFileDir = 'data\\\\NYC_Store_clean.csv'\n",
    "##############3#storesData.to_csv(outFileDir)\n",
    "storesData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#describ stores\n",
    "#storesData.groupby('Address ZIP').count().head(2)\n",
    "#############storesData.groupby(['Address ZIP','License Type']).count().drop(['Address City','License Expiration Date'],axis=1)\\\n",
    "#############                .to_csv('data\\\\NYC_Store_Count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "University/College - long/lat - zip\n",
    "Museum - zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "univData = pd.read_csv('rowData\\\\COLLEGE_UNIVERSITY.csv', encoding='latin1')\n",
    "univCount = storesData.groupby(['Address ZIP']).count().drop(['Address City','License Expiration Date','License Type'],axis=1)\n",
    "univCount['count'] = 0\n",
    "univCount=univCount.drop(['DCA License Number'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#univCount.loc['10011']\n",
    "univRange = 5\n",
    "for index, row in univData.iterrows():\n",
    "    #univCount.loc[str(row.ZIP)] = univCount.loc[str(row.ZIP)]+1\n",
    "    geomstr = row['the_geom']\n",
    "    geom = geomstr.split()\n",
    "    long = geom[1][1:]\n",
    "    lat = geom[2][:-1]\n",
    "    zips = trans_geo2zip(float(lat),float(long),univRange)\n",
    "    pior = univRange\n",
    "    for zip_dis in zips:\n",
    "        zipIdx = str(zip_dis[0])\n",
    "        #check index\n",
    "        if zipIdx in univCount.index:\n",
    "            univCount.loc[zipIdx] =  univCount.loc[zipIdx] + pior\n",
    "        else:\n",
    "            univCount.loc[zipIdx] = 0\n",
    "        pior = pior - 1\n",
    "#univCount.to_csv('data\\\\NYC_Univ_zip_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "musData = pd.read_csv('rowData\\\\MUSEUM.csv', encoding='latin1')\n",
    "musCount = univCount.drop(['count'],axis=1)\n",
    "musCount['count']=0\n",
    "musRange = 5\n",
    "for index, row in musData.iterrows():\n",
    "    geomstr = row['the_geom']\n",
    "    geom = geomstr.split()\n",
    "    long = geom[1][1:]\n",
    "    lat = geom[2][:-1]\n",
    "    zips = trans_geo2zip(float(lat),float(long),musRange)\n",
    "    pior = musRange\n",
    "    for zip_dis in zips:\n",
    "        zipIdx = str(zip_dis[0])\n",
    "        #check index\n",
    "        if zipIdx in musCount.index:\n",
    "            musCount.loc[zipIdx] =  musCount.loc[zipIdx] + pior\n",
    "        else:\n",
    "            musCount.loc[zipIdx] = 0\n",
    "        pior = pior - 1\n",
    "#musCount.to_csv('data\\\\NYC_Mus_zip_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [10001, 10002, 10003, 10004, 10005, 10006, 10007, 10008, 10009, 10010, 10011, 10012, 10013, 10014, 10016, 10017, 10018, 10019, 10020, 10021, 10022, 10023, 10024, 10025, 10026, 10027, 10028, 10029, 10030, 10031, 10032, 10033, 10034, 10035, 10036, 10037, 10038, 10039, 10040, 10041, 10044, 10055, 10065, 10069, 10075, 10080, 10101, 10103, 10105, 10106, 10107, 10108, 10112, 10116, 10118, 10119, 10120, 10121, 10122, 10123, 10128, 10150, 10151, 10152, 10153, 10154, 10155, 10156, 10158, 10159, 10162, 10163, 10165, 10166, 10167, 10168, 10169, 10170, 10171, 10172, 10173, 10174, 10175, 10176, 10178, 10185, 10271, 10276, 10279, 10280, 10281, 10282, 10301, 10302, 10303, 10304, 10305, 10306, 10307, 10308, ...]\n",
      "\n",
      "[557 rows x 0 columns]\n"
     ]
    }
   ],
   "source": [
    "libData = pd.read_csv('rowData\\\\LIBRARY.csv', encoding='latin1')\n",
    "libCount = univCount.drop(['count'],axis=1)\n",
    "libCount['count']=0\n",
    "libRange = 3\n",
    "for index, row in libData.iterrows():\n",
    "    geomstr = row['the_geom']\n",
    "    geom = geomstr.split()\n",
    "    long = geom[1][1:]\n",
    "    lat = geom[2][:-1]\n",
    "    zips = trans_geo2zip(float(lat),float(long),libRange)\n",
    "    pior = libRange\n",
    "    for zip_dis in zips:\n",
    "        zipIdx = str(zip_dis[0])\n",
    "        #check index\n",
    "        if zipIdx in libCount.index:\n",
    "            libCount.loc[zipIdx] =  libCount.loc[zipIdx] + pior\n",
    "        else:\n",
    "            libCount.loc[zipIdx] = 0\n",
    "        pior = pior - 1\n",
    "#musCount.to_csv('data\\\\NYC_Lib_zip_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
